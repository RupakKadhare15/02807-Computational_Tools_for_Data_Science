{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16bc6d3",
   "metadata": {},
   "source": [
    "# Step 1 - CRSS Data Extraction & Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058e6fd",
   "metadata": {},
   "source": [
    "This is the code for the first step of the CRSS data pipeline.\n",
    "\n",
    "In summary:\n",
    "* Load the 3 CRSS data files (Person, Vehicle, Accident)\n",
    "* Join them at person level (most granular)\n",
    "* Delete duplicate features\n",
    "* Replace \"Not reported\" or \"unknown\" codes with null values\n",
    "* Create FATALITY indicator based on MAX_SEV\n",
    "\n",
    "Missing code handling is based on the CRSS Analytical User's Manual. Different features use different codes for \"unknown\" or \"not reported\" (e.g., 99, 999, 9999). These are mapped to null values.\n",
    "\n",
    "Note: This code is optimized for CRSS 2016-2023 data. Earlier years may have different missing value codes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c6cc2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8aaf08",
   "metadata": {},
   "source": [
    "### How to run the code:\n",
    "Run all the sections in order (top to bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d9d46",
   "metadata": {},
   "source": [
    "##### CRSS field-specific missing codes (based on CRSS Analytical User's Manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f02298f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRSS field-specific missing codes (based on CRSS Analytical User's Manual 2016-2023)\n",
    "FIELD_SPECIFIC_MISSING = {\n",
    "    \n",
    "    # Demographics\n",
    "    \"AGE\": [998, 999],\n",
    "    \"SEX\": [8, 9],\n",
    "    \"RACE\": [97, 98, 99],\n",
    "    \"HISPANIC\": [8, 9, 98, 99],\n",
    "    \n",
    "    # Temporal\n",
    "    \"HOUR\": [99, 9999],  # CRSS uses both\n",
    "    \"MINUTE\": [99, 999],\n",
    "    \"DAY\": [99],\n",
    "    \"MONTH\": [99],\n",
    "    \"DAY_WEEK\": [9],\n",
    "    \n",
    "    # Injury/Outcome\n",
    "    \"INJ_SEV\": [9],\n",
    "    \"MAX_SEV\": [8,9],  # Important for CRSS!\n",
    "    \"DEATH_HR\": [9999],  # Not 88, 99\n",
    "    \"DEATH_MN\": [999],   # Not 88, 99\n",
    "    \n",
    "    # Behaviors - Substance Use\n",
    "    \"DRINKING\": [8, 9, 98, 99],\n",
    "    \"DR_DRINK\": [8, 9, 98, 99],  # Added\n",
    "    \"DRUGS\": [95, 96, 97, 98, 99],  # Not just [8, 9]\n",
    "    \"DRUG_DET\": [5, 6, 8, 9, 95, 96, 97, 98, 99],  # Not just [8]\n",
    "    \"DRUGRES1\": [95, 96, 97, 98, 99],  # Not [95, 999]\n",
    "    \"DRUGRES2\": [95, 96, 97, 98, 99],\n",
    "    \"DRUGRES3\": [95, 96, 97, 98, 99],\n",
    "    # DO NOT include \"ALC_RES\" - mixed variable, handled separately!\n",
    "    \"ALC_STATUS\": [8, 9],  # Added\n",
    "    \"ALC_DET\": [8, 9],     # Added\n",
    "    \n",
    "    # Behaviors - Safety Equipment\n",
    "    \"REST_USE\": [8, 9, 98, 99],  # Not [20, 96, 98, 99]\n",
    "    \"REST_MIS\": [8, 9, 98, 99],  # Not just [7, 8]\n",
    "    \"AIR_BAG\": [8, 9, 98, 99],   # Not just [98, 99]\n",
    "    \"HELM_USE\": [8, 9],\n",
    "    \"HELM_MIS\": [8, 9], \n",
    "    \"SPEEDREL\": [9],\n",
    "    \n",
    "    # Behaviors - Ejection\n",
    "    \"EJECTION\": [8, 9],\n",
    "    \"EJ_PATH\": [8, 9],\n",
    "    \"EXTRICAT\": [8, 9],\n",
    "    \n",
    "    # Vehicle\n",
    "    \"BODY_TYP\": [78, 79, 97, 98, 99],\n",
    "    \"MOD_YEAR\": [9999],     \n",
    "    \"GVWR\": [9],            \n",
    "    \"V_CONFIG\": [9],        \n",
    "    \"CARGO_BT\": [9],        \n",
    "    \"HAZ_INV\": [9],         \n",
    "    \"BUS_USE\": [9],         \n",
    "    \"SPEC_USE\": [9],        \n",
    "    \"EMER_USE\": [9],   \n",
    "    \"ROLLOVER\": [9],\n",
    "    \"ROLINLOC\": [9], \n",
    "    \"IMPACT1\": [98, 99],\n",
    "    \"FIRE_EXP\": [8, 9],\n",
    "    \"FIRE\": [8, 9],\n",
    "    \"DEFORMED\": [9],\n",
    "    \"VEH_SEV\": [9],\n",
    "    \"TOWED\": [9],\n",
    "    \"M_HARM\": [98, 99],     # Most harmful event (vehicle level)\n",
    "    \"VEH_CF1\": [98, 99],    # Vehicle contributing factors\n",
    "    \"VEH_CF2\": [98, 99],\n",
    "    \"NUMOCCS\": [99],        # Number of occupants\n",
    "    \n",
    "    # Environmental\n",
    "    \"WEATHER\": [98, 99],\n",
    "    \"WEATHER1\": [10, 98, 99],  # Note: 10 added for CRSS vs FARS\n",
    "    \"WEATHER2\": [98, 99],\n",
    "    \"LGT_COND\": [9],        # Not [8, 9]\n",
    "    \n",
    "    # Location\n",
    "    \"RUR_URB\": [9],         # Not [8, 9]\n",
    "    \"FUNC_SYS\": [9],        # Not [98, 99]\n",
    "    \"LATITUDE\": [77.7777, 88.8888, 99.9999],\n",
    "    \"LONGITUD\": [777.7777, 888.8888, 999.9999],\n",
    "    \n",
    "    # Roadway\n",
    "    \"HARM_EV\": [98, 99],    # Correct\n",
    "    \"MAN_COLL\": [9],        # Not [98, 99]\n",
    "    \"RELJCT1\": [98, 99],    # Not [8, 9]\n",
    "    \"RELJCT2\": [98, 99],    # Not just [98, 99]\n",
    "    \"TYP_INT\": [99],        # Not [98, 99]\n",
    "    \"WRK_ZONE\": [9],\n",
    "    \"REL_ROAD\": [9],        # Not [98, 99]\n",
    "    \"VTRAFWAY\": [9],        # Not [8, 9]\n",
    "    \"VNUM_LAN\": [9],        # Not [8, 9]\n",
    "    \"VSPD_LIM\": [98, 99],\n",
    "    \"VALIGN\": [9],\n",
    "    \"VPROFILE\": [9],        # Not [8, 9]\n",
    "    \"VPAVETYP\": [9],        # Not [8, 9]\n",
    "    \"VSURCOND\": [9],        # Not [98, 99]\n",
    "    \"VTRAFCON\": [98, 99],   # Not [97, 99]\n",
    "    \n",
    "    # Person-specific\n",
    "    \"PER_TYP\": [19],     # Not just [19]\n",
    "    \"SEAT_POS\": [98, 99],\n",
    "    \"SEATING\": [98, 99],    # Removed in recent CRSS\n",
    "    \n",
    "    # Notification/arrival times\n",
    "    \"NOT_HOUR\": [99, 9999],   # Not [88, 99]\n",
    "    \"NOT_MIN\": [99, 999],     # Not [88, 98, 99]\n",
    "    \"ARR_HOUR\": [99, 9999],   # Not [88, 99]\n",
    "    \"ARR_MIN\": [99, 999],     # Not [88, 98, 99]\n",
    "    \"HOSP_HR\": [99, 9999],    # Not [88, 99]\n",
    "    \"HOSP_MN\": [99, 999],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b8cf1",
   "metadata": {},
   "source": [
    "##### Numeric columns (common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d3b82033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default numeric columns if not specified\n",
    "NUMERIC_COLUMNS = [\n",
    "    # ========================================\n",
    "    # IDs and Keys\n",
    "    # ========================================\n",
    "    #\"CASENUM\",      # CRSS case number (primary key)\n",
    "    \"ST_CASE\",      # State case number\n",
    "    \"VEH_NO\",       # Vehicle number\n",
    "    \"PER_NO\",       # Person number\n",
    "    \"STATE\",        # State code\n",
    "    \"COUNTY\",       # County code\n",
    "    \n",
    "    # ========================================\n",
    "    # Survey Design Variables (CRITICAL!)\n",
    "    # ========================================\n",
    "    \"PSU\",          # Primary Sampling Unit\n",
    "    \"PJ\",           # Jackknife replicate\n",
    "    \"REGION\",       # Region code\n",
    "    \"STRATUM\",      # Stratum code\n",
    "    \"PSUSTRAT\",     # PSU within stratum\n",
    "    \"PSU_VAR\",      # PSU for variance estimation\n",
    "    \n",
    "    # ========================================\n",
    "    # Weights (ESSENTIAL FOR ANALYSIS!)\n",
    "    # ========================================\n",
    "    #\"WEIGHT\",       # Survey weight - represents population\n",
    "    \"RATWGT\",       # Ratio adjustment weight\n",
    "    \n",
    "    # ========================================\n",
    "    # Demographics\n",
    "    # ========================================\n",
    "    \"AGE\",          # Person age (0-120, 998-999 = missing)\n",
    "    \"SEX\",          # Sex (1=Male, 2=Female, 8-9=Unknown)\n",
    "    \"RACE\",         # Race code\n",
    "    \"HISPANIC\",     # Hispanic origin\n",
    "    \n",
    "    # ========================================\n",
    "    # Temporal\n",
    "    # ========================================\n",
    "    \"YEAR\",         # Crash year\n",
    "    \"MONTH\",        # Month (1-12)\n",
    "    \"DAY\",          # Day of month\n",
    "    \"DAY_WEEK\",     # Day of week (1-7)\n",
    "    \"HOUR\",         # Hour (0-23, 99/9999=Unknown)\n",
    "    \"MINUTE\",       # Minute (0-59, 99/999=Unknown)\n",
    "    \n",
    "    # ========================================\n",
    "    # Outcomes (Person Level)\n",
    "    # ========================================\n",
    "    \"INJ_SEV\",      # Injury severity (person)\n",
    "    \"MAX_SEV\",      # Maximum severity in crash (CRITICAL!)\n",
    "    \"DEATH_HR\",     # Hours to death (9999=Unknown)\n",
    "    \"DEATH_MN\",     # Minutes to death (999=Unknown)\n",
    "    \n",
    "    # ========================================\n",
    "    # Person Behavior\n",
    "    # ========================================\n",
    "    \"PER_TYP\",      # Person type (driver, passenger, pedestrian, etc.)\n",
    "    \"SEAT_POS\",     # Seating position\n",
    "    \"REST_USE\",     # Restraint use (seatbelt type)\n",
    "    \"REST_MIS\",     # Restraint misuse\n",
    "    \"AIR_BAG\",      # Air bag deployment\n",
    "    \"EJECTION\",     # Ejection status\n",
    "    \"EJ_PATH\",      # Ejection path\n",
    "    \"EXTRICAT\",     # Extrication required\n",
    "    \"HELM_USE\",     # Helmet use (motorcycles)\n",
    "    \"HELM_MIS\",     # Helmet misuse\n",
    "    \n",
    "    # ========================================\n",
    "    # Substance Use\n",
    "    # ========================================\n",
    "    \"DRINKING\",     # Police reported alcohol involvement\n",
    "    \"DR_DRINK\",     # Driver drinking\n",
    "    \"ALC_RES\",      # Alcohol test result (MIXED VARIABLE!)\n",
    "    \"ALC_STATUS\",   # Alcohol test status\n",
    "    \"ALC_DET\",      # Alcohol detection method\n",
    "    \"DRUGS\",        # Police reported drug involvement\n",
    "    \"DRUG_DET\",     # Drug test method\n",
    "    \"DRUGRES1\",     # Drug test result 1\n",
    "    \"DRUGRES2\",     # Drug test result 2\n",
    "    \"DRUGRES3\",     # Drug test result 3\n",
    "    \n",
    "    # ========================================\n",
    "    # Vehicle Characteristics\n",
    "    # ========================================\n",
    "    \"BODY_TYP\",     # Vehicle body type\n",
    "    \"MOD_YEAR\",     # Model year (1900-2100, 9999=Unknown)\n",
    "    \"MAKE\",         # Vehicle make\n",
    "    \"MODEL\",        # Vehicle model\n",
    "    \"MAK_MOD\",      # Combined make/model code\n",
    "    \"GVWR\",         # Gross vehicle weight rating\n",
    "    \"V_CONFIG\",     # Vehicle configuration\n",
    "    \"BUS_USE\",      # Bus use\n",
    "    \"SPEC_USE\",     # Special use\n",
    "    \"EMER_USE\",     # Emergency use\n",
    "    \"CARGO_BT\",     # Cargo body type\n",
    "    \"HAZ_INV\",      # Hazmat involved\n",
    "    \"NUMOCCS\",      # Number of occupants in vehicle\n",
    "    \n",
    "    # ========================================\n",
    "    # Crash Dynamics\n",
    "    # ========================================\n",
    "    \"ROLLOVER\",     # Rollover occurrence\n",
    "    \"ROLINLOC\",     # Rollover location\n",
    "    \"IMPACT1\",      # Initial impact point\n",
    "    \"FIRE_EXP\",     # Fire/explosion (old name)\n",
    "    \"FIRE\",         # Fire occurrence (CRSS name)\n",
    "    \"DEFORMED\",     # Extent of damage (CRSS)\n",
    "    \"VEH_SEV\",      # Vehicle severity (CRSS)\n",
    "    \"TOWED\",        # Vehicle towed (replaces TOW_VEH)\n",
    "    \"M_HARM\",       # Most harmful event (vehicle level)\n",
    "    \"VEH_CF1\",      # Vehicle contributing factor 1\n",
    "    \"VEH_CF2\",      # Vehicle contributing factor 2\n",
    "    \"SPEEDREL\",     # Speed related\n",
    "    \n",
    "    # ========================================\n",
    "    # Environmental\n",
    "    # ========================================\n",
    "    \"WEATHER\",      # Weather condition\n",
    "    \"WEATHER1\",     # Weather condition 1\n",
    "    \"WEATHER2\",     # Weather condition 2\n",
    "    \"LGT_COND\",     # Light condition\n",
    "    \n",
    "    # ========================================\n",
    "    # Location/Geography\n",
    "    # ========================================\n",
    "    \"RUR_URB\",      # Rural/Urban\n",
    "    \"FUNC_SYS\",     # Functional system\n",
    "    \"LATITUDE\",     # Latitude coordinate\n",
    "    \"LONGITUD\",     # Longitude coordinate\n",
    "    \"URBANICITY\",   # Urban/rural classification (some CRSS years)\n",
    "    \n",
    "    # ========================================\n",
    "    # Crash/Roadway Characteristics\n",
    "    # ========================================\n",
    "    \"HARM_EV\",      # First harmful event (crash level)\n",
    "    \"MAN_COLL\",     # Manner of collision\n",
    "    \"RELJCT1\",      # Junction relation 1\n",
    "    \"RELJCT2\",      # Junction relation 2\n",
    "    \"TYP_INT\",      # Intersection type\n",
    "    \"WRK_ZONE\",     # Work zone\n",
    "    \"REL_ROAD\",     # Relation to roadway\n",
    "    \"VTRAFWAY\",     # Trafficway description\n",
    "    \"VNUM_LAN\",     # Number of travel lanes\n",
    "    \"VALIGN\",       # Roadway alignment\n",
    "    \"VPROFILE\",     # Roadway profile\n",
    "    \"VPAVETYP\",     # Pavement type\n",
    "    \"VSURCOND\",     # Surface condition\n",
    "    \"VTRAFCON\",     # Traffic control device\n",
    "    \n",
    "    # ========================================\n",
    "    # Notification/Response Times\n",
    "    # ========================================\n",
    "    \"NOT_HOUR\",     # Notification hour\n",
    "    \"NOT_MIN\",      # Notification minute\n",
    "    \"ARR_HOUR\",     # EMS arrival hour\n",
    "    \"ARR_MIN\",      # EMS arrival minute\n",
    "    \"HOSP_HR\",      # Hospital arrival hour\n",
    "    \"HOSP_MN\",      # Hospital arrival minute\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf136d",
   "metadata": {},
   "source": [
    "### Step 1.1: Data Loading\n",
    "Load CRSS CSV files with columns as strings to prevent conversion issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d88a8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crss_csv(filename: str, data_dir: Path) -> pl.DataFrame:\n",
    "    path = Path(data_dir) / filename\n",
    "    \n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    \n",
    "    # Load with no schema inference\n",
    "    df = pl.read_csv(path, infer_schema_length=0)\n",
    "    \n",
    "    print(f\"Loaded: {filename}\")\n",
    "    print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ad68d",
   "metadata": {},
   "source": [
    "### Step 1.2: Key Validation\n",
    "\n",
    "Remove duplicates and review null keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5fd1fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_keys(\n",
    "    df: pl.DataFrame,\n",
    "    key_columns: List[str]\n",
    ") -> pl.DataFrame:\n",
    "    # Check for NULL keys\n",
    "    for col in key_columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        null_count = df.filter(pl.col(col).is_null()).height\n",
    "        if null_count > 0:\n",
    "            print(f\"NULL values in {col}: {null_count:,}\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    original_count = df.height\n",
    "    df_unique = df.unique(subset=key_columns, maintain_order=True)\n",
    "    duplicates = original_count - df_unique.height\n",
    "    \n",
    "    if duplicates > 0:\n",
    "        print(f\"Removed {duplicates:,} duplicate rows\")\n",
    "    else: \n",
    "        print(f\"No duplicates found\")\n",
    "    \n",
    "    return df_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d13e2",
   "metadata": {},
   "source": [
    "### Step 1.3: Data Type Conversion\n",
    "\n",
    "Convert the specified columns from string to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "13e23d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numeric(\n",
    "    df: pl.DataFrame,\n",
    "    columns: List[str]\n",
    ") -> pl.DataFrame:\n",
    "\n",
    "    converted = 0\n",
    "    errors = 0\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Skip if already numeric\n",
    "        if df[col].dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64,\n",
    "                             pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64,\n",
    "                             pl.Float32, pl.Float64]:\n",
    "            converted += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            df = df.with_columns(\n",
    "                pl.col(col).cast(pl.Int32, strict=False).alias(col)\n",
    "            )\n",
    "            converted += 1\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "    \n",
    "    print(f\"Converted {converted} columns to numeric\")\n",
    "    if errors > 0:\n",
    "        print(f\"Errors in {errors} columns\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f16db",
   "metadata": {},
   "source": [
    "### Step 1.4: Missing Code Handling\n",
    "Use the field-specific missing codes dictionary to apply the missing code handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a5f77699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_field_specific_missing_codes(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    total_replaced = 0\n",
    "    columns_modified = 0\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Get field-specific missing codes\n",
    "        if col in FIELD_SPECIFIC_MISSING:\n",
    "            missing_codes = FIELD_SPECIFIC_MISSING[col]\n",
    "        else:\n",
    "            # Skip columns not in numeric list and not explicitly defined\n",
    "            if col not in NUMERIC_COLUMNS:\n",
    "                continue\n",
    "        \n",
    "        try:\n",
    "            col_dtype = df[col].dtype\n",
    "            \n",
    "            if col_dtype == pl.Utf8:\n",
    "                # String column\n",
    "                missing_code_strs = [str(c) for c in missing_codes if isinstance(c, int)]\n",
    "                if \"\" in missing_codes:\n",
    "                    missing_code_strs.append(\"\")\n",
    "                \n",
    "                count_before = df.filter(pl.col(col).is_in(missing_code_strs)).height\n",
    "                # if the code is one of the missing codes, it is converted to None to prevent influencing the analysis results\n",
    "                if count_before > 0:\n",
    "                    df = df.with_columns(\n",
    "                        pl.when(pl.col(col).is_in(missing_code_strs))\n",
    "                        .then(None)\n",
    "                        .otherwise(pl.col(col))\n",
    "                        .alias(col)\n",
    "                    )\n",
    "                    total_replaced += count_before\n",
    "                    columns_modified += 1\n",
    "            \n",
    "            elif col_dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64,\n",
    "                               pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64,\n",
    "                               pl.Float32, pl.Float64]:\n",
    "                # Numeric column\n",
    "                numeric_codes = [c for c in missing_codes if isinstance(c, (int, float))]\n",
    "                \n",
    "                count_before = df.filter(pl.col(col).is_in(numeric_codes)).height\n",
    "                \n",
    "                if count_before > 0:\n",
    "                    df = df.with_columns(\n",
    "                        pl.when(pl.col(col).is_in(numeric_codes))\n",
    "                        .then(None)\n",
    "                        .otherwise(pl.col(col))\n",
    "                        .alias(col)\n",
    "                    )\n",
    "                    total_replaced += count_before\n",
    "                    columns_modified += 1\n",
    "        \n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    print(f\" Replaced missing codes in {columns_modified} columns\")\n",
    "    print(f\" Total replacements: {total_replaced:,}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c11d97",
   "metadata": {},
   "source": [
    "### Step 1.5: Dataset Integration\n",
    "\n",
    "* Integrate person, vehicle, and accident datasets into person-level data\n",
    "\n",
    "* Join hierarchy: person (base) → vehicle → accident\n",
    "\n",
    "* Overlapped columns are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "987d18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_person_vehicle_accident(\n",
    "    person: pl.DataFrame,\n",
    "    vehicle: pl.DataFrame,\n",
    "    accident: pl.DataFrame\n",
    ") -> pl.DataFrame:\n",
    "\n",
    "    # Identify overlapping columns\n",
    "    vehicle_cols = set(vehicle.columns)\n",
    "    person_cols = set(person.columns)\n",
    "    accident_cols = set(accident.columns)\n",
    "    \n",
    "    # Drop overlapping columns from vehicle (keep join keys)\n",
    "    vehicle_person_overlap = (vehicle_cols & person_cols) - {\"CASE_NUM\", \"VEH_NO\"}\n",
    "    if vehicle_person_overlap:\n",
    "        vehicle = vehicle.drop(list(vehicle_person_overlap))\n",
    "    \n",
    "    # Drop overlapping columns from accident (keep join keys)\n",
    "    accident_person_overlap = (accident_cols & person_cols) - {\"CASE_NUM\"}\n",
    "    if accident_person_overlap:\n",
    "        accident = accident.drop(list(accident_person_overlap))\n",
    "    \n",
    "    # Join person → vehicle\n",
    "    per_veh = person.join(vehicle, on=[\"CASE_NUM\", \"VEH_NO\"], how=\"left\")\n",
    "    \n",
    "    # Join person-vehicle → accident\n",
    "    per_full = per_veh.join(accident, on=\"CASE_NUM\", how=\"left\")\n",
    "    \n",
    "    return per_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbedfed",
   "metadata": {},
   "source": [
    "### Create pipeline of data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9b3ea0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_step1_pipeline_CRSS(\n",
    "    data_dir: Path,\n",
    "    output_file: Optional[Path] = None,\n",
    "    numeric_columns: Optional[List[str]] = None\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    CRSS-only pipeline: reads CRSS accident/vehicle/person CSVs,\n",
    "    keeps CRSS-native column names, and integrates to person level.\n",
    "    Adds accident-level fatality flag: FATALITY = 1 if MAX_SEV indicates fatal injury, else 0.\n",
    "    Keys used:\n",
    "      - Accident: CASENUM\n",
    "      - Vehicle:  CASENUM, VEH_NO\n",
    "      - Person:   CASENUM, VEH_NO, PER_NO\n",
    "    \"\"\"\n",
    "    # default numeric columns fallback\n",
    "    if numeric_columns is None:\n",
    "        numeric_columns = NUMERIC_COLUMNS\n",
    "\n",
    "    accident = load_crss_csv(\"accident.csv\", data_dir)\n",
    "    vehicle  = load_crss_csv(\"vehicle.csv\",  data_dir)\n",
    "    person   = load_crss_csv(\"person.csv\",   data_dir)\n",
    "\n",
    "\n",
    "    # Validate keys \n",
    "    for name, df, keys in [\n",
    "        (\"accident\", accident, [\"CASENUM\"]),\n",
    "        (\"vehicle\",  vehicle,  [\"CASENUM\", \"VEH_NO\"]),\n",
    "        (\"person\",   person,   [\"CASENUM\", \"VEH_NO\", \"PER_NO\"]),\n",
    "    ]:\n",
    "        missing = [k for k in keys if k not in df.columns]\n",
    "        if missing:\n",
    "            raise KeyError(f\"{name} missing expected key(s): {missing}\")\n",
    "\n",
    "    # Drop duplicate rows by keys\n",
    "    accident = remove_duplicate_keys(accident, [\"CASENUM\"])\n",
    "    vehicle  = remove_duplicate_keys(vehicle,  [\"CASENUM\", \"VEH_NO\"])\n",
    "    person   = remove_duplicate_keys(person,   [\"CASENUM\", \"VEH_NO\", \"PER_NO\"])\n",
    "\n",
    "\n",
    "    # Numeric conversions\n",
    "    accident = convert_to_numeric(accident, numeric_columns)\n",
    "    vehicle  = convert_to_numeric(vehicle,  numeric_columns)\n",
    "    person   = convert_to_numeric(person,   numeric_columns)\n",
    "\n",
    "    # Keep only vehicle occupants in person table\n",
    "    person = person.filter(pl.col(\"PER_TYP\").is_in([1, 2, 3, 4, 9]))\n",
    "    print(f\"  per_typ unique values: {sorted(person['PER_TYP'].unique())}\")\n",
    "\n",
    "    # Missing-code handling\n",
    "    accident = replace_field_specific_missing_codes(accident)\n",
    "    vehicle  = replace_field_specific_missing_codes(vehicle)\n",
    "    person   = replace_field_specific_missing_codes(person)\n",
    "    \n",
    "    # Create accident-level fatality flag (cast MAX_SEV first to avoid type errors)\n",
    "    if \"MAX_SEV\" in accident.columns:\n",
    "        accident = accident.with_columns(\n",
    "            pl.when(pl.col(\"MAX_SEV\").cast(pl.Int32, strict=False) == 4)\n",
    "              .then(1)\n",
    "              .otherwise(0)\n",
    "              .alias(\"FATALITY\")\n",
    "        )\n",
    "       \n",
    "    else:\n",
    "        accident = accident.with_columns(pl.lit(0).alias(\"FATALITY\"))\n",
    "\n",
    "    # Integrate to person level with CRSS keys\n",
    "    df_integrated = (\n",
    "        person.join(vehicle, on=[\"CASENUM\", \"VEH_NO\"], how=\"left\", suffix=\"_veh\")\n",
    "              .join(accident, on=[\"CASENUM\"], how=\"left\", suffix=\"_acc\")\n",
    "    )\n",
    "\n",
    "    # 7) Save (optional)\n",
    "    if output_file is not None:\n",
    "        output_path = Path(output_file)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df_integrated.write_parquet(output_path)\n",
    "        print(f\"Saved parquet to: {output_path}\")\n",
    "\n",
    "    print(f\"Final CRSS dataset: {df_integrated.shape[0]:,} rows × {df_integrated.shape[1]} columns\")\n",
    "    return df_integrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a0a88",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ddd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: accident.csv\n",
      "Shape: 50,103 rows × 80 columns\n",
      "Loaded: vehicle.csv\n",
      "Shape: 87,461 rows × 169 columns\n",
      "Loaded: person.csv\n",
      "Shape: 122,388 rows × 112 columns\n",
      "No duplicates found\n",
      "No duplicates found\n",
      "No duplicates found\n",
      "Converted 22 columns to numeric\n",
      "Converted 38 columns to numeric\n",
      "Converted 38 columns to numeric\n",
      "  per_typ unique values: [1, 2, 3, 4, 9]\n",
      " Replaced missing codes in 9 columns\n",
      " Total replacements: 3,946\n",
      " Replaced missing codes in 21 columns\n",
      " Total replacements: 34,636\n",
      " Replaced missing codes in 19 columns\n",
      " Total replacements: 152,108\n",
      "Saved parquet to: data/step1_preprocessed_final/person_level_integrated_CRSS.parquet\n",
      "Final CRSS dataset: 117,033 rows × 359 columns\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path(\"data/CRSS2023CSV\")\n",
    "OUTPUT_FILE = Path(\"Dataset_Regression/person_level_integrated_CRSS.parquet\")\n",
    "\n",
    "# Run complete pipeline\n",
    "df = run_step1_pipeline_CRSS(\n",
    "    data_dir=DATA_DIR,\n",
    "    output_file=OUTPUT_FILE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
