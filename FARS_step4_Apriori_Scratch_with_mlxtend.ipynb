{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16bc6d3",
   "metadata": {},
   "source": [
    "# Step 4 - Association Rule Mining with Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058e6fd",
   "metadata": {},
   "source": [
    "This code requires the following file to run:\n",
    "- St3_fatal_accident_clusters.parquet\n",
    "\n",
    "-------------------------\n",
    "\n",
    "This is the code for the fourth step of our pipeline.\n",
    "In summary:\n",
    "* Load clustered driver data from previous step\n",
    "* Transform data into transaction format for association rule mining\n",
    "* Implement Apriori algorithm from scratch for finding frequent itemsets\n",
    "* Compare scratch implementation with mlxtend library implementation\n",
    "* Generate association rules with support, confidence, and lift metrics\n",
    "* Analyze rules for each cluster to identify patterns\n",
    "* Display top rules ranked by lift to find strongest associations\n",
    "\n",
    "The Apriori algorithm discovers interesting relationships (association rules) between features in the data. For example, it can identify that \"drivers in dark conditions\" → \"nighttime accidents\" with high confidence. The algorithm is useful for understanding which combinations of features frequently occur together in fatal accidents.\n",
    "\n",
    "Both a scratch implementation and the mlxtend library are used for validation and comparison.\n",
    "\n",
    "A limitation of this approach is that the minimum support and confidence thresholds must be carefully tuned. Too high thresholds may miss interesting rules, while too low thresholds generate too many trivial rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8aaf08",
   "metadata": {},
   "source": [
    "### How to run the code:\n",
    "\n",
    "1) Run libraries\n",
    "2) Run all the sections in order (top to bottom)\n",
    "3) Run the Use section\n",
    "4) Optional: review the code of each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cc2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set, Tuple, Optional\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e4ef5",
   "metadata": {},
   "source": [
    "### Step 4.1: Transaction Preparation\n",
    "\n",
    "Convert clustered data into transaction format for association rule mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02298f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transactions_for_cluster(\n",
    "    df: pd.DataFrame, \n",
    "    cluster_id: int,\n",
    "    categorical_cols: List[str],\n",
    "    binary_cols: List[str]\n",
    ") -> List[List[str]]:\n",
    "\n",
    "    df_c = df[df['cluster'] == cluster_id].copy()\n",
    "    \n",
    "    transactions = []\n",
    "    for _, row in df_c.iterrows():\n",
    "        transaction = []\n",
    "        \n",
    "        # Add categorical attributes (Column=Value format), can be changed in USE\n",
    "        for col in categorical_cols:\n",
    "            if pd.notna(row[col]):\n",
    "                transaction.append(f\"{col}={row[col]}\")\n",
    "        \n",
    "        # Add binary attributes (Column name if value is 1), can be changed in USE\n",
    "        for col in binary_cols:\n",
    "            if row[col] == 1:\n",
    "                transaction.append(col)\n",
    "        \n",
    "        transactions.append(transaction)\n",
    "    \n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d9d46",
   "metadata": {},
   "source": [
    "### Step 4.2: Apriori Algorithm - Scratch Implementation\n",
    "\n",
    "Core functions for Apriori algorithm implemented from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b82033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_C1(dataset: List[List[str]]) -> List[frozenset]:\n",
    "    C1 = []\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            if [item] not in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1))\n",
    "\n",
    "\n",
    "def scan_D(\n",
    "    dataset: List[List[str]], \n",
    "    candidates: List[frozenset], \n",
    "    min_support: float\n",
    ") -> Tuple[List[frozenset], Dict[frozenset, float]]:\n",
    "\n",
    "    ss_cnt = {}\n",
    "    \n",
    "    # Count occurrences of each candidate\n",
    "    for tid in dataset:\n",
    "        for can in candidates:\n",
    "            if can.issubset(tid):\n",
    "                if can not in ss_cnt:\n",
    "                    ss_cnt[can] = 1\n",
    "                else:\n",
    "                    ss_cnt[can] += 1\n",
    "    \n",
    "    # Calculate support and filter by min_support\n",
    "    num_items = float(len(dataset))\n",
    "    ret_list = []\n",
    "    support_data = {}\n",
    "    \n",
    "    for key in ss_cnt:\n",
    "        support = ss_cnt[key] / num_items\n",
    "        if support >= min_support:\n",
    "            ret_list.insert(0, key)\n",
    "        support_data[key] = support\n",
    "    \n",
    "    return ret_list, support_data\n",
    "\n",
    "\n",
    "def apriori_gen(Lk: List[frozenset], k: int) -> List[frozenset]:\n",
    "\n",
    "    ret_list = []\n",
    "    len_Lk = len(Lk)\n",
    "    \n",
    "    for i in range(len_Lk):\n",
    "        for j in range(i + 1, len_Lk):\n",
    "            # Join step: merge itemsets with k-2 common items\n",
    "            L1 = list(Lk[i])[:k-2]\n",
    "            L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            \n",
    "            if L1 == L2: # Join step\n",
    "                ret_list.append(Lk[i] | Lk[j])\n",
    "    \n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b8cf1",
   "metadata": {},
   "source": [
    "### Step 4.3: Apriori Main Algorithm (Scratch)\n",
    "\n",
    "Main Apriori algorithm to find all frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987d18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_scratch(\n",
    "    dataset: List[List[str]], \n",
    "    min_support: float = 0.4\n",
    ") -> Tuple[List[List[frozenset]], Dict[frozenset, float]]:\n",
    "\n",
    "    # Convert to frozenset for efficient subset operations\n",
    "    dataset_frozen = list(map(set, dataset))\n",
    "    \n",
    "    # Generate initial candidates (size 1)\n",
    "    C1 = create_C1(dataset)\n",
    "    \n",
    "    # Find frequent 1-itemsets\n",
    "    L1, support_data = scan_D(dataset_frozen, C1, min_support)\n",
    "    \n",
    "    # Store all frequent itemsets\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    \n",
    "    # Iteratively find larger itemsets\n",
    "    while len(L[k-2]) > 0:\n",
    "        # Generate candidates of size k\n",
    "        Ck = apriori_gen(L[k-2], k)\n",
    "        \n",
    "        # Find frequent k-itemsets\n",
    "        Lk, supK = scan_D(dataset_frozen, Ck, min_support)\n",
    "        \n",
    "        support_data.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    \n",
    "    return L, support_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee6c1e",
   "metadata": {},
   "source": [
    "### Step 4.4: Association Rule Generation (Scratch)\n",
    "\n",
    "Generate association rules from frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e4236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_conf(\n",
    "    freq_set: frozenset,\n",
    "    H: List[frozenset],\n",
    "    support_data: Dict[frozenset, float],\n",
    "    brl: List[Tuple],\n",
    "    min_conf: float\n",
    ") -> List[frozenset]:\n",
    "\n",
    "    pruned_H = []\n",
    "    \n",
    "    for conseq in H:\n",
    "        antecedent = freq_set - conseq\n",
    "\n",
    "        # Calculate confidence: support(freq_set) / support(antecedent)\n",
    "        conf = support_data[freq_set] / support_data[antecedent]\n",
    "        \n",
    "        if conf >= min_conf:\n",
    "            # Calculate lift: confidence / support(consequent)\n",
    "            lift = conf / support_data[conseq]\n",
    "            \n",
    "            brl.append((antecedent, conseq, conf, lift, support_data[freq_set]))\n",
    "            pruned_H.append(conseq)\n",
    "    \n",
    "    return pruned_H\n",
    "\n",
    "\n",
    "def rules_from_conseq(\n",
    "    freq_set: frozenset,\n",
    "    H: List[frozenset],\n",
    "    support_data: Dict[frozenset, float],\n",
    "    brl: List[Tuple],\n",
    "    min_conf: float\n",
    ") -> None:\n",
    "    \n",
    "    m = len(H[0])  # Size of current consequents\n",
    "    \n",
    "    if len(freq_set) > (m + 1):\n",
    "        Hmp1 = apriori_gen(H, m + 1)\n",
    "    \n",
    "        # Test these candidates and prune\n",
    "        Hmp1 = calc_conf(freq_set, Hmp1, support_data, brl, min_conf)\n",
    "        if len(Hmp1) > 1:\n",
    "            rules_from_conseq(freq_set, Hmp1, support_data, brl, min_conf)\n",
    "\n",
    "\n",
    "def generate_rules_scratch(\n",
    "    L: List[List[frozenset]], \n",
    "    support_data: Dict[frozenset, float],\n",
    "    min_confidence: float = 0.6\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    big_rule_list = []\n",
    "    \n",
    "    # Start from L[1] (2-itemsets) since we need at least 2 items for a rule\n",
    "    for i in range(1, len(L)):\n",
    "        for freq_set in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freq_set]\n",
    "            \n",
    "            # 1. Always calculate confidence for 1-item consequents first\n",
    "            H1 = calc_conf(freq_set, H1, support_data, big_rule_list, min_confidence)\n",
    "            \n",
    "            # 2. If itemset has more than 2 items AND we have valid consequents, recurse\n",
    "            if i > 1 and len(H1) > 0:\n",
    "                rules_from_conseq(freq_set, H1, support_data, big_rule_list, min_confidence)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    rules = []\n",
    "    for (antecedents, consequents, confidence, lift, support) in big_rule_list:\n",
    "        rules.append({\n",
    "            'antecedents': ', '.join(sorted(antecedents)),\n",
    "            'consequents': ', '.join(sorted(consequents)),\n",
    "            'support': support,\n",
    "            'confidence': confidence,\n",
    "            'lift': lift\n",
    "        })\n",
    "    \n",
    "    df_rules = pd.DataFrame(rules)\n",
    "    \n",
    "    if len(df_rules) > 0:\n",
    "        df_rules = df_rules.sort_values('lift', ascending=False)\n",
    "    \n",
    "    return df_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe0009",
   "metadata": {},
   "source": [
    "### Step 4.5: Apriori with mlxtend Library\n",
    "\n",
    "Use mlxtend library for comparison and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4546450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_mlxtend(\n",
    "    transactions: List[List[str]],\n",
    "    min_support: float = 0.4,\n",
    "    min_confidence: float = 0.6\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    # Transform transactions to one-hot encoded DataFrame\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    # Find frequent itemsets\n",
    "    frequent_itemsets = apriori(\n",
    "        df_encoded, \n",
    "        min_support=min_support, \n",
    "        use_colnames=True\n",
    "    )\n",
    "    \n",
    "    # Generate rules\n",
    "    if len(frequent_itemsets) > 0:\n",
    "        rules = association_rules(\n",
    "            frequent_itemsets,\n",
    "            metric=\"confidence\",\n",
    "            min_threshold=min_confidence\n",
    "        )\n",
    "        \n",
    "        # Format for consistency with scratch implementation\n",
    "        if len(rules) > 0:\n",
    "            rules['antecedents'] = rules['antecedents'].apply(\n",
    "                lambda x: ', '.join(sorted(list(x)))\n",
    "            )\n",
    "            rules['consequents'] = rules['consequents'].apply(\n",
    "                lambda x: ', '.join(sorted(list(x)))\n",
    "            )\n",
    "            rules = rules[['antecedents', 'consequents', 'support', \n",
    "                          'confidence', 'lift']].sort_values('lift', ascending=False)\n",
    "    else:\n",
    "        rules = pd.DataFrame()\n",
    "    \n",
    "    return frequent_itemsets, rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b7cf5",
   "metadata": {},
   "source": [
    "### Step 4.6: Cluster Analysis Function\n",
    "\n",
    "Analyze association rules for a specific cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7198c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cluster_rules(\n",
    "    df: pd.DataFrame,\n",
    "    cluster_id: int,\n",
    "    categorical_cols: List[str],\n",
    "    binary_cols: List[str],\n",
    "    min_support: float = 0.4,\n",
    "    min_confidence: float = 0.6,\n",
    "    top_n: int = 15\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "\n",
    "    # Get transactions for this cluster\n",
    "    transactions = get_transactions_for_cluster(\n",
    "        df, cluster_id, categorical_cols, binary_cols\n",
    "    )\n",
    "    print(f\"Transactions: {len(transactions)}\")\n",
    "    \n",
    "    # Method 1: Scratch implementation\n",
    "    print(\"\\n--- [SCRATCH] Running Apriori from scratch...\")\n",
    "    L_scratch, support_data_scratch = apriori_scratch(transactions, min_support)\n",
    "    rules_scratch = generate_rules_scratch(L_scratch, support_data_scratch, min_confidence)\n",
    "    \n",
    "    print(f\"\\n--- [SCRATCH] Top {top_n} Rules ---\\n\")\n",
    "    if len(rules_scratch) > 0:\n",
    "        display_df = rules_scratch.head(top_n).copy()\n",
    "        display_df.columns = [col.capitalize() for col in display_df.columns]\n",
    "        # Format numeric columns to 3 decimals\n",
    "        display_df['Support'] = display_df['Support'].map('{:.3f}'.format)\n",
    "        display_df['Confidence'] = display_df['Confidence'].map('{:.3f}'.format)\n",
    "        display_df['Lift'] = display_df['Lift'].map('{:.3f}'.format)\n",
    "        print(display_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No rules found with current thresholds.\")\n",
    "    \n",
    "    # Method 2: mlxtend library\n",
    "    print(\"\\n--- [MLXTEND] Running Apriori with mlxtend...\")\n",
    "    freq_itemsets_mlx, rules_mlxtend = apriori_mlxtend(\n",
    "        transactions, min_support, min_confidence\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- [MLXTEND] Top {top_n} Rules ---\\n\")\n",
    "    if len(rules_mlxtend) > 0:\n",
    "        display_df = rules_mlxtend.head(top_n).copy()\n",
    "        display_df.columns = [col.capitalize() for col in display_df.columns]\n",
    "        # Format numeric columns to 3 decimals\n",
    "        display_df['Support'] = display_df['Support'].map('{:.3f}'.format)\n",
    "        display_df['Confidence'] = display_df['Confidence'].map('{:.3f}'.format)\n",
    "        display_df['Lift'] = display_df['Lift'].map('{:.3f}'.format)\n",
    "        print(display_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No rules found with current thresholds.\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'scratch': rules_scratch,\n",
    "        'mlxtend': rules_mlxtend\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c11d97",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "Run association rule mining for all clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd22fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_apriori_pipeline(\n",
    "    input_file: Path,\n",
    "    categorical_cols: List[str],\n",
    "    binary_cols: List[str],\n",
    "    min_support: float = 0.4,\n",
    "    min_confidence: float = 0.6,\n",
    "    clusters_to_analyze: Optional[List[int]] = None,\n",
    "    top_n: int = 15,\n",
    "    save_results: bool = True,\n",
    "    output_dir: Optional[Path] = None\n",
    ") -> Dict[int, Dict[str, pd.DataFrame]]:\n",
    "\n",
    "    print(\"ASSOCIATION RULE MINING WITH APRIORI\")\n",
    "    print(f\"\\nConfiguration:\")\n",
    "    print(f\"   Min Support: {min_support}\")\n",
    "    print(f\"   Min Confidence: {min_confidence}\")\n",
    "    print(f\"   Binary features: {len(binary_cols)}\")\n",
    "    print(f\"   Categorical features: {len(categorical_cols)}\")\n",
    "    print()\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"Loading data from: {input_file}\")\n",
    "    df = pd.read_parquet(input_file)\n",
    "    print(f\"Loaded: {len(df):,} drivers\")\n",
    "    \n",
    "    # Determine clusters to analyze\n",
    "    if clusters_to_analyze is None:\n",
    "        clusters_to_analyze = sorted(df['cluster'].unique())\n",
    "    \n",
    "    print(f\"Analyzing {len(clusters_to_analyze)} clusters: {clusters_to_analyze}\\n\")\n",
    "    \n",
    "    # Analyze each cluster\n",
    "    all_results = {}\n",
    "    \n",
    "    for cluster_id in clusters_to_analyze:\n",
    "        results = analyze_cluster_rules(\n",
    "            df=df,\n",
    "            cluster_id=cluster_id,\n",
    "            categorical_cols=categorical_cols,\n",
    "            binary_cols=binary_cols,\n",
    "            min_support=min_support,\n",
    "            min_confidence=min_confidence,\n",
    "            top_n=top_n\n",
    "        )\n",
    "        all_results[cluster_id] = results\n",
    "        \n",
    "        # Save results if requested\n",
    "        if save_results and output_dir is not None:\n",
    "            output_path = Path(output_dir)\n",
    "            output_path.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Save scratch rules\n",
    "            if len(results['scratch']) > 0:\n",
    "                scratch_file = output_path / f\"cluster_{cluster_id}_rules_scratch.csv\"\n",
    "                results['scratch'].to_csv(scratch_file, index=False)\n",
    "            \n",
    "            # Save mlxtend rules\n",
    "            if len(results['mlxtend']) > 0:\n",
    "                mlxtend_file = output_path / f\"cluster_{cluster_id}_rules_mlxtend.csv\"\n",
    "                results['mlxtend'].to_csv(mlxtend_file, index=False)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"   • Clusters analyzed: {len(clusters_to_analyze)}\")\n",
    "    print(f\"   • Min support: {min_support}\")\n",
    "    print(f\"   • Min confidence: {min_confidence}\")\n",
    "    \n",
    "    # Count total rules found\n",
    "    total_rules_scratch = sum(len(r['scratch']) for r in all_results.values())\n",
    "    total_rules_mlxtend = sum(len(r['mlxtend']) for r in all_results.values())\n",
    "    print(f\"   • Total rules found (scratch): {total_rules_scratch}\")\n",
    "    print(f\"   • Total rules found (mlxtend): {total_rules_mlxtend}\")\n",
    "    \n",
    "    if save_results and output_dir is not None:\n",
    "        print(f\"\\nResults saved to: {output_dir}\")\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc1223",
   "metadata": {},
   "source": [
    "### USE\n",
    "\n",
    "Configure INPUT path, features, and Apriori parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97968ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSOCIATION RULE MINING WITH APRIORI\n",
      "\n",
      "Configuration:\n",
      "   Min Support: 0.4\n",
      "   Min Confidence: 0.6\n",
      "   Binary features: 14\n",
      "   Categorical features: 4\n",
      "\n",
      "Loading data from: Dataset\\St3_fatal_accident_clusters.parquet\n",
      "Loaded: 55,725 drivers\n",
      "Analyzing 6 clusters: [np.uint16(0), np.uint16(1), np.uint16(2), np.uint16(3), np.uint16(4), np.uint16(5)]\n",
      "\n",
      "Transactions: 26348\n",
      "\n",
      "--- [SCRATCH] Running Apriori from scratch...\n",
      "\n",
      "--- [SCRATCH] Top 15 Rules ---\n",
      "\n",
      "                Antecedents                Consequents Support Confidence  Lift\n",
      "                      URBAN                       MALE   0.504      0.761 1.024\n",
      "                       MALE                      URBAN   0.504      0.679 1.024\n",
      "                      URBAN MALE, WEEKEND_FLAG=Weekday   0.401      0.605 1.023\n",
      " MALE, WEEKEND_FLAG=Weekday                      URBAN   0.401      0.678 1.023\n",
      "              PASSENGER_CAR                      URBAN   0.484      0.674 1.017\n",
      "                      URBAN              PASSENGER_CAR   0.484      0.730 1.017\n",
      "                      URBAN            AGE_GROUP=Adult   0.431      0.650 1.015\n",
      "            AGE_GROUP=Adult                      URBAN   0.431      0.673 1.015\n",
      "            AGE_GROUP=Adult                       MALE   0.480      0.750 1.009\n",
      "                       MALE            AGE_GROUP=Adult   0.480      0.646 1.009\n",
      "                      URBAN       WEEKEND_FLAG=Weekday   0.539      0.813 1.003\n",
      "       WEEKEND_FLAG=Weekday                      URBAN   0.539      0.665 1.003\n",
      "URBAN, WEEKEND_FLAG=Weekday                       MALE   0.401      0.744 1.001\n",
      "            AGE_GROUP=Adult       WEEKEND_FLAG=Weekday   0.519      0.810 0.999\n",
      "       WEEKEND_FLAG=Weekday            AGE_GROUP=Adult   0.519      0.640 0.999\n",
      "\n",
      "--- [MLXTEND] Running Apriori with mlxtend...\n",
      "\n",
      "--- [MLXTEND] Top 15 Rules ---\n",
      "\n",
      "                Antecedents                Consequents Support Confidence  Lift\n",
      "                      URBAN                       MALE   0.504      0.761 1.024\n",
      "                       MALE                      URBAN   0.504      0.679 1.024\n",
      " MALE, WEEKEND_FLAG=Weekday                      URBAN   0.401      0.678 1.023\n",
      "                      URBAN MALE, WEEKEND_FLAG=Weekday   0.401      0.605 1.023\n",
      "              PASSENGER_CAR                      URBAN   0.484      0.674 1.017\n",
      "                      URBAN              PASSENGER_CAR   0.484      0.730 1.017\n",
      "            AGE_GROUP=Adult                      URBAN   0.431      0.673 1.015\n",
      "                      URBAN            AGE_GROUP=Adult   0.431      0.650 1.015\n",
      "            AGE_GROUP=Adult                       MALE   0.480      0.750 1.009\n",
      "                       MALE            AGE_GROUP=Adult   0.480      0.646 1.009\n",
      "                      URBAN       WEEKEND_FLAG=Weekday   0.539      0.813 1.003\n",
      "       WEEKEND_FLAG=Weekday                      URBAN   0.539      0.665 1.003\n",
      "URBAN, WEEKEND_FLAG=Weekday                       MALE   0.401      0.744 1.001\n",
      "       WEEKEND_FLAG=Weekday            AGE_GROUP=Adult   0.519      0.640 0.999\n",
      "            AGE_GROUP=Adult       WEEKEND_FLAG=Weekday   0.519      0.810 0.999\n",
      "\n",
      "\n",
      "Transactions: 5653\n",
      "\n",
      "--- [SCRATCH] Running Apriori from scratch...\n",
      "\n",
      "--- [SCRATCH] Top 15 Rules ---\n",
      "\n",
      "                          Antecedents                           Consequents Support Confidence  Lift\n",
      "AGE_GROUP=Adult, WEEKEND_FLAG=Weekday                             RUSH_HOUR   0.468      0.739 1.066\n",
      "                            RUSH_HOUR AGE_GROUP=Adult, WEEKEND_FLAG=Weekday   0.468      0.674 1.066\n",
      "               OLD_VEHICLE, RUSH_HOUR                  WEEKEND_FLAG=Weekday   0.410      1.000 1.060\n",
      "                            RUSH_HOUR                  WEEKEND_FLAG=Weekday   0.693      1.000 1.060\n",
      "                      MALE, RUSH_HOUR                  WEEKEND_FLAG=Weekday   0.552      1.000 1.060\n",
      "                 WEEKEND_FLAG=Weekday                             RUSH_HOUR   0.693      0.735 1.060\n",
      "           AGE_GROUP=Adult, RUSH_HOUR                  WEEKEND_FLAG=Weekday   0.468      1.000 1.060\n",
      "           MALE, WEEKEND_FLAG=Weekday                             RUSH_HOUR   0.552      0.715 1.031\n",
      "                            RUSH_HOUR            MALE, WEEKEND_FLAG=Weekday   0.552      0.797 1.031\n",
      "    OLD_VEHICLE, WEEKEND_FLAG=Weekday                                  MALE   0.487      0.835 1.017\n",
      "                          OLD_VEHICLE                                  MALE   0.522      0.834 1.016\n",
      "                                 MALE                           OLD_VEHICLE   0.522      0.636 1.016\n",
      "    OLD_VEHICLE, WEEKEND_FLAG=Weekday                             RUSH_HOUR   0.410      0.704 1.015\n",
      "                                 MALE                          INTERSECTION   0.494      0.602 1.008\n",
      "                         INTERSECTION                                  MALE   0.494      0.827 1.008\n",
      "\n",
      "--- [MLXTEND] Running Apriori with mlxtend...\n",
      "\n",
      "--- [MLXTEND] Top 15 Rules ---\n",
      "\n",
      "                          Antecedents                           Consequents Support Confidence  Lift\n",
      "                            RUSH_HOUR AGE_GROUP=Adult, WEEKEND_FLAG=Weekday   0.468      0.674 1.066\n",
      "AGE_GROUP=Adult, WEEKEND_FLAG=Weekday                             RUSH_HOUR   0.468      0.739 1.066\n",
      "                 WEEKEND_FLAG=Weekday                             RUSH_HOUR   0.693      0.735 1.060\n",
      "                            RUSH_HOUR                  WEEKEND_FLAG=Weekday   0.693      1.000 1.060\n",
      "                      MALE, RUSH_HOUR                  WEEKEND_FLAG=Weekday   0.552      1.000 1.060\n",
      "               OLD_VEHICLE, RUSH_HOUR                  WEEKEND_FLAG=Weekday   0.410      1.000 1.060\n",
      "           AGE_GROUP=Adult, RUSH_HOUR                  WEEKEND_FLAG=Weekday   0.468      1.000 1.060\n",
      "           MALE, WEEKEND_FLAG=Weekday                             RUSH_HOUR   0.552      0.715 1.031\n",
      "                            RUSH_HOUR            MALE, WEEKEND_FLAG=Weekday   0.552      0.797 1.031\n",
      "    OLD_VEHICLE, WEEKEND_FLAG=Weekday                                  MALE   0.487      0.835 1.017\n",
      "                          OLD_VEHICLE                                  MALE   0.522      0.834 1.016\n",
      "                                 MALE                           OLD_VEHICLE   0.522      0.636 1.016\n",
      "    OLD_VEHICLE, WEEKEND_FLAG=Weekday                             RUSH_HOUR   0.410      0.704 1.015\n",
      "                                 MALE                          INTERSECTION   0.494      0.602 1.008\n",
      "                         INTERSECTION                                  MALE   0.494      0.827 1.008\n",
      "\n",
      "\n",
      "Transactions: 9296\n",
      "\n",
      "--- [SCRATCH] Running Apriori from scratch...\n",
      "\n",
      "--- [SCRATCH] Top 15 Rules ---\n",
      "\n",
      "                             Antecedents                            Consequents Support Confidence  Lift\n",
      "  AGE_GROUP=Adult, DARK_CONDITIONS, MALE                      TIME_OF_DAY=Night   0.401      0.754 1.191\n",
      "                       TIME_OF_DAY=Night AGE_GROUP=Adult, DARK_CONDITIONS, MALE   0.401      0.634 1.191\n",
      "      AGE_GROUP=Adult, TIME_OF_DAY=Night                  DARK_CONDITIONS, MALE   0.401      0.900 1.180\n",
      "                   DARK_CONDITIONS, MALE                      TIME_OF_DAY=Night   0.569      0.746 1.179\n",
      "                       TIME_OF_DAY=Night                  DARK_CONDITIONS, MALE   0.569      0.899 1.179\n",
      "        AGE_GROUP=Adult, DARK_CONDITIONS                MALE, TIME_OF_DAY=Night   0.401      0.671 1.176\n",
      "                 MALE, TIME_OF_DAY=Night       AGE_GROUP=Adult, DARK_CONDITIONS   0.401      0.703 1.176\n",
      "        AGE_GROUP=Adult, DARK_CONDITIONS                      TIME_OF_DAY=Night   0.445      0.744 1.176\n",
      "                       TIME_OF_DAY=Night       AGE_GROUP=Adult, DARK_CONDITIONS   0.445      0.702 1.176\n",
      "AGE_GROUP=Adult, MALE, TIME_OF_DAY=Night                        DARK_CONDITIONS   0.401      0.998 1.166\n",
      "      AGE_GROUP=Adult, TIME_OF_DAY=Night                        DARK_CONDITIONS   0.445      0.998 1.165\n",
      "                         DARK_CONDITIONS                MALE, TIME_OF_DAY=Night   0.569      0.665 1.164\n",
      "                 MALE, TIME_OF_DAY=Night                        DARK_CONDITIONS   0.569      0.997 1.164\n",
      "                       TIME_OF_DAY=Night                        DARK_CONDITIONS   0.631      0.997 1.164\n",
      "                         DARK_CONDITIONS                      TIME_OF_DAY=Night   0.631      0.737 1.164\n",
      "\n",
      "--- [MLXTEND] Running Apriori with mlxtend...\n",
      "\n",
      "--- [MLXTEND] Top 15 Rules ---\n",
      "\n",
      "                             Antecedents                            Consequents Support Confidence  Lift\n",
      "  AGE_GROUP=Adult, DARK_CONDITIONS, MALE                      TIME_OF_DAY=Night   0.401      0.754 1.191\n",
      "                       TIME_OF_DAY=Night AGE_GROUP=Adult, DARK_CONDITIONS, MALE   0.401      0.634 1.191\n",
      "      AGE_GROUP=Adult, TIME_OF_DAY=Night                  DARK_CONDITIONS, MALE   0.401      0.900 1.180\n",
      "                   DARK_CONDITIONS, MALE                      TIME_OF_DAY=Night   0.569      0.746 1.179\n",
      "                       TIME_OF_DAY=Night                  DARK_CONDITIONS, MALE   0.569      0.899 1.179\n",
      "        AGE_GROUP=Adult, DARK_CONDITIONS                MALE, TIME_OF_DAY=Night   0.401      0.671 1.176\n",
      "                 MALE, TIME_OF_DAY=Night       AGE_GROUP=Adult, DARK_CONDITIONS   0.401      0.703 1.176\n",
      "        AGE_GROUP=Adult, DARK_CONDITIONS                      TIME_OF_DAY=Night   0.445      0.744 1.176\n",
      "                       TIME_OF_DAY=Night       AGE_GROUP=Adult, DARK_CONDITIONS   0.445      0.702 1.176\n",
      "AGE_GROUP=Adult, MALE, TIME_OF_DAY=Night                        DARK_CONDITIONS   0.401      0.998 1.166\n",
      "      AGE_GROUP=Adult, TIME_OF_DAY=Night                        DARK_CONDITIONS   0.445      0.998 1.165\n",
      "                         DARK_CONDITIONS                MALE, TIME_OF_DAY=Night   0.569      0.665 1.164\n",
      "                 MALE, TIME_OF_DAY=Night                        DARK_CONDITIONS   0.569      0.997 1.164\n",
      "                         DARK_CONDITIONS                      TIME_OF_DAY=Night   0.631      0.737 1.164\n",
      "                       TIME_OF_DAY=Night                        DARK_CONDITIONS   0.631      0.997 1.164\n",
      "\n",
      "\n",
      "Transactions: 4804\n",
      "\n",
      "--- [SCRATCH] Running Apriori from scratch...\n",
      "\n",
      "--- [SCRATCH] Top 15 Rules ---\n",
      "\n",
      "                     Antecedents                Consequents Support Confidence  Lift\n",
      "MALE, TIME_OF_DAY=Evening, URBAN            DARK_CONDITIONS   0.415      0.871 1.208\n",
      "                 DARK_CONDITIONS TIME_OF_DAY=Evening, URBAN   0.437      0.606 1.205\n",
      "      TIME_OF_DAY=Evening, URBAN            DARK_CONDITIONS   0.437      0.868 1.205\n",
      "       MALE, TIME_OF_DAY=Evening            DARK_CONDITIONS   0.472      0.861 1.195\n",
      "                 DARK_CONDITIONS  MALE, TIME_OF_DAY=Evening   0.472      0.655 1.195\n",
      "      TIME_OF_DAY=Evening, URBAN      DARK_CONDITIONS, MALE   0.415      0.825 1.193\n",
      "           DARK_CONDITIONS, MALE TIME_OF_DAY=Evening, URBAN   0.415      0.601 1.193\n",
      "                 DARK_CONDITIONS        TIME_OF_DAY=Evening   0.497      0.690 1.192\n",
      "             TIME_OF_DAY=Evening            DARK_CONDITIONS   0.497      0.859 1.192\n",
      "           DARK_CONDITIONS, MALE        TIME_OF_DAY=Evening   0.472      0.683 1.180\n",
      "             TIME_OF_DAY=Evening      DARK_CONDITIONS, MALE   0.472      0.816 1.180\n",
      "          DARK_CONDITIONS, URBAN  MALE, TIME_OF_DAY=Evening   0.415      0.638 1.164\n",
      "       MALE, TIME_OF_DAY=Evening     DARK_CONDITIONS, URBAN   0.415      0.757 1.164\n",
      "          DARK_CONDITIONS, URBAN        TIME_OF_DAY=Evening   0.437      0.672 1.161\n",
      "             TIME_OF_DAY=Evening     DARK_CONDITIONS, URBAN   0.437      0.755 1.161\n",
      "\n",
      "--- [MLXTEND] Running Apriori with mlxtend...\n",
      "\n",
      "--- [MLXTEND] Top 15 Rules ---\n",
      "\n",
      "                     Antecedents                Consequents Support Confidence  Lift\n",
      "MALE, TIME_OF_DAY=Evening, URBAN            DARK_CONDITIONS   0.415      0.871 1.208\n",
      "      TIME_OF_DAY=Evening, URBAN            DARK_CONDITIONS   0.437      0.868 1.205\n",
      "                 DARK_CONDITIONS TIME_OF_DAY=Evening, URBAN   0.437      0.606 1.205\n",
      "       MALE, TIME_OF_DAY=Evening            DARK_CONDITIONS   0.472      0.861 1.195\n",
      "                 DARK_CONDITIONS  MALE, TIME_OF_DAY=Evening   0.472      0.655 1.195\n",
      "      TIME_OF_DAY=Evening, URBAN      DARK_CONDITIONS, MALE   0.415      0.825 1.193\n",
      "           DARK_CONDITIONS, MALE TIME_OF_DAY=Evening, URBAN   0.415      0.601 1.193\n",
      "                 DARK_CONDITIONS        TIME_OF_DAY=Evening   0.497      0.690 1.192\n",
      "             TIME_OF_DAY=Evening            DARK_CONDITIONS   0.497      0.859 1.192\n",
      "             TIME_OF_DAY=Evening      DARK_CONDITIONS, MALE   0.472      0.816 1.180\n",
      "           DARK_CONDITIONS, MALE        TIME_OF_DAY=Evening   0.472      0.683 1.180\n",
      "          DARK_CONDITIONS, URBAN  MALE, TIME_OF_DAY=Evening   0.415      0.638 1.164\n",
      "       MALE, TIME_OF_DAY=Evening     DARK_CONDITIONS, URBAN   0.415      0.757 1.164\n",
      "          DARK_CONDITIONS, URBAN        TIME_OF_DAY=Evening   0.437      0.672 1.161\n",
      "             TIME_OF_DAY=Evening     DARK_CONDITIONS, URBAN   0.437      0.755 1.161\n",
      "\n",
      "\n",
      "Transactions: 6768\n",
      "\n",
      "--- [SCRATCH] Running Apriori from scratch...\n",
      "\n",
      "--- [SCRATCH] Top 15 Rules ---\n",
      "\n",
      "                            Antecedents                           Consequents Support Confidence  Lift\n",
      "                      TIME_OF_DAY=Night                DARK_CONDITIONS, URBAN   0.513      0.877 1.207\n",
      "                 DARK_CONDITIONS, URBAN                     TIME_OF_DAY=Night   0.513      0.706 1.207\n",
      "       PASSENGER_CAR, TIME_OF_DAY=Night                DARK_CONDITIONS, URBAN   0.496      0.876 1.206\n",
      "                 DARK_CONDITIONS, URBAN      PASSENGER_CAR, TIME_OF_DAY=Night   0.496      0.683 1.206\n",
      "  DARK_CONDITIONS, PASSENGER_CAR, URBAN                     TIME_OF_DAY=Night   0.496      0.702 1.201\n",
      "                      TIME_OF_DAY=Night DARK_CONDITIONS, PASSENGER_CAR, URBAN   0.496      0.848 1.201\n",
      "                        DARK_CONDITIONS                     TIME_OF_DAY=Night   0.584      0.682 1.165\n",
      "                      TIME_OF_DAY=Night                       DARK_CONDITIONS   0.584      0.998 1.165\n",
      "                        DARK_CONDITIONS      PASSENGER_CAR, TIME_OF_DAY=Night   0.565      0.660 1.165\n",
      "       PASSENGER_CAR, TIME_OF_DAY=Night                       DARK_CONDITIONS   0.565      0.998 1.165\n",
      "               TIME_OF_DAY=Night, URBAN                       DARK_CONDITIONS   0.513      0.998 1.165\n",
      "PASSENGER_CAR, TIME_OF_DAY=Night, URBAN                       DARK_CONDITIONS   0.496      0.998 1.165\n",
      "                      TIME_OF_DAY=Night        DARK_CONDITIONS, PASSENGER_CAR   0.565      0.967 1.158\n",
      "         DARK_CONDITIONS, PASSENGER_CAR                     TIME_OF_DAY=Night   0.565      0.677 1.158\n",
      "               TIME_OF_DAY=Night, URBAN        DARK_CONDITIONS, PASSENGER_CAR   0.496      0.965 1.157\n",
      "\n",
      "--- [MLXTEND] Running Apriori with mlxtend...\n",
      "\n",
      "--- [MLXTEND] Top 15 Rules ---\n",
      "\n",
      "                            Antecedents                           Consequents Support Confidence  Lift\n",
      "                 DARK_CONDITIONS, URBAN                     TIME_OF_DAY=Night   0.513      0.706 1.207\n",
      "                      TIME_OF_DAY=Night                DARK_CONDITIONS, URBAN   0.513      0.877 1.207\n",
      "       PASSENGER_CAR, TIME_OF_DAY=Night                DARK_CONDITIONS, URBAN   0.496      0.876 1.206\n",
      "                 DARK_CONDITIONS, URBAN      PASSENGER_CAR, TIME_OF_DAY=Night   0.496      0.683 1.206\n",
      "  DARK_CONDITIONS, PASSENGER_CAR, URBAN                     TIME_OF_DAY=Night   0.496      0.702 1.201\n",
      "                      TIME_OF_DAY=Night DARK_CONDITIONS, PASSENGER_CAR, URBAN   0.496      0.848 1.201\n",
      "                        DARK_CONDITIONS                     TIME_OF_DAY=Night   0.584      0.682 1.165\n",
      "                      TIME_OF_DAY=Night                       DARK_CONDITIONS   0.584      0.998 1.165\n",
      "       PASSENGER_CAR, TIME_OF_DAY=Night                       DARK_CONDITIONS   0.565      0.998 1.165\n",
      "                        DARK_CONDITIONS      PASSENGER_CAR, TIME_OF_DAY=Night   0.565      0.660 1.165\n",
      "               TIME_OF_DAY=Night, URBAN                       DARK_CONDITIONS   0.513      0.998 1.165\n",
      "PASSENGER_CAR, TIME_OF_DAY=Night, URBAN                       DARK_CONDITIONS   0.496      0.998 1.165\n",
      "                      TIME_OF_DAY=Night        DARK_CONDITIONS, PASSENGER_CAR   0.565      0.967 1.158\n",
      "         DARK_CONDITIONS, PASSENGER_CAR                     TIME_OF_DAY=Night   0.565      0.677 1.158\n",
      "               TIME_OF_DAY=Night, URBAN        DARK_CONDITIONS, PASSENGER_CAR   0.496      0.965 1.157\n",
      "\n",
      "\n",
      "Transactions: 2856\n",
      "\n",
      "--- [SCRATCH] Running Apriori from scratch...\n",
      "\n",
      "--- [SCRATCH] Top 15 Rules ---\n",
      "\n",
      "                                Antecedents                                 Consequents Support Confidence  Lift\n",
      "      DARK_CONDITIONS, WEEKEND_FLAG=Weekday                         TIME_OF_DAY=Evening   0.414      0.601 1.199\n",
      "                        TIME_OF_DAY=Evening       DARK_CONDITIONS, WEEKEND_FLAG=Weekday   0.414      0.826 1.199\n",
      "                        TIME_OF_DAY=Evening                             DARK_CONDITIONS   0.435      0.867 1.193\n",
      "  TIME_OF_DAY=Evening, WEEKEND_FLAG=Weekday                             DARK_CONDITIONS   0.414      0.867 1.193\n",
      "          LARGE_TRUCK, WEEKEND_FLAG=Weekday                       AGE_GROUP=Adult, MALE   0.461      0.849 1.169\n",
      "                      AGE_GROUP=Adult, MALE           LARGE_TRUCK, WEEKEND_FLAG=Weekday   0.461      0.635 1.169\n",
      "                      AGE_GROUP=Adult, MALE                                 LARGE_TRUCK   0.502      0.691 1.164\n",
      "                                LARGE_TRUCK                       AGE_GROUP=Adult, MALE   0.502      0.845 1.164\n",
      "                                LARGE_TRUCK AGE_GROUP=Adult, MALE, WEEKEND_FLAG=Weekday   0.461      0.777 1.139\n",
      "AGE_GROUP=Adult, MALE, WEEKEND_FLAG=Weekday                                 LARGE_TRUCK   0.461      0.676 1.139\n",
      "          LARGE_TRUCK, WEEKEND_FLAG=Weekday                             AGE_GROUP=Adult   0.480      0.882 1.087\n",
      "    LARGE_TRUCK, MALE, WEEKEND_FLAG=Weekday                             AGE_GROUP=Adult   0.461      0.881 1.086\n",
      "                                 INTERSTATE                       AGE_GROUP=Adult, MALE   0.421      0.785 1.082\n",
      "                            AGE_GROUP=Adult                                 LARGE_TRUCK   0.521      0.642 1.081\n",
      "                                LARGE_TRUCK                             AGE_GROUP=Adult   0.521      0.877 1.081\n",
      "\n",
      "--- [MLXTEND] Running Apriori with mlxtend...\n",
      "\n",
      "--- [MLXTEND] Top 15 Rules ---\n",
      "\n",
      "                                Antecedents                                 Consequents Support Confidence  Lift\n",
      "      DARK_CONDITIONS, WEEKEND_FLAG=Weekday                         TIME_OF_DAY=Evening   0.414      0.601 1.199\n",
      "                        TIME_OF_DAY=Evening       DARK_CONDITIONS, WEEKEND_FLAG=Weekday   0.414      0.826 1.199\n",
      "                        TIME_OF_DAY=Evening                             DARK_CONDITIONS   0.435      0.867 1.193\n",
      "  TIME_OF_DAY=Evening, WEEKEND_FLAG=Weekday                             DARK_CONDITIONS   0.414      0.867 1.193\n",
      "          LARGE_TRUCK, WEEKEND_FLAG=Weekday                       AGE_GROUP=Adult, MALE   0.461      0.849 1.169\n",
      "                      AGE_GROUP=Adult, MALE           LARGE_TRUCK, WEEKEND_FLAG=Weekday   0.461      0.635 1.169\n",
      "                                LARGE_TRUCK                       AGE_GROUP=Adult, MALE   0.502      0.845 1.164\n",
      "                      AGE_GROUP=Adult, MALE                                 LARGE_TRUCK   0.502      0.691 1.164\n",
      "                                LARGE_TRUCK AGE_GROUP=Adult, MALE, WEEKEND_FLAG=Weekday   0.461      0.777 1.139\n",
      "AGE_GROUP=Adult, MALE, WEEKEND_FLAG=Weekday                                 LARGE_TRUCK   0.461      0.676 1.139\n",
      "          LARGE_TRUCK, WEEKEND_FLAG=Weekday                             AGE_GROUP=Adult   0.480      0.882 1.087\n",
      "    LARGE_TRUCK, MALE, WEEKEND_FLAG=Weekday                             AGE_GROUP=Adult   0.461      0.881 1.086\n",
      "                                 INTERSTATE                       AGE_GROUP=Adult, MALE   0.421      0.785 1.082\n",
      "                            AGE_GROUP=Adult                                 LARGE_TRUCK   0.521      0.642 1.081\n",
      "                                LARGE_TRUCK                             AGE_GROUP=Adult   0.521      0.877 1.081\n",
      "\n",
      "\n",
      "\n",
      "Summary:\n",
      "   • Clusters analyzed: 6\n",
      "   • Min support: 0.4\n",
      "   • Min confidence: 0.6\n",
      "   • Total rules found (scratch): 478\n",
      "   • Total rules found (mlxtend): 478\n",
      "\n",
      "Results saved to: Results\\St4_apriori_results\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# INPUT Configuration\n",
    "INPUT_FILE = Path(\"Dataset/St3_fatal_accident_clusters.parquet\")\n",
    "OUTPUT_DIR = Path(\"Results/St4_apriori_results\")\n",
    "\n",
    "# Features Configuration (must match Step 3)\n",
    "CATEGORICAL_COLS = [\n",
    "    'TIME_OF_DAY',\n",
    "    'WEEKEND_FLAG',\n",
    "    'SEASON',\n",
    "    'AGE_GROUP'\n",
    "]\n",
    "\n",
    "BINARY_COLS = [\n",
    "    'RUSH_HOUR',\n",
    "    'MALE',\n",
    "    'ADVERSE_WEATHER',\n",
    "    'DARK_CONDITIONS',\n",
    "    'OLD_VEHICLE',\n",
    "    'PASSENGER_CAR',\n",
    "    'LARGE_TRUCK',\n",
    "    'MOTORCYCLE',\n",
    "    'URBAN',\n",
    "    'INTERSTATE',\n",
    "    'INTERSECTION',\n",
    "    'WORK_ZONE_CRASH',\n",
    "    'ROLLOVER_CRASH',\n",
    "    'FIRE'\n",
    "]\n",
    "\n",
    "# Apriori Parameters\n",
    "MIN_SUPPORT = 0.4  # Minimum support threshold (40%)\n",
    "MIN_CONFIDENCE = 0.6  # Minimum confidence threshold (60%)\n",
    "TOP_N_RULES = 15  # Number of top rules to display per cluster\n",
    "\n",
    "# Analysis Configuration\n",
    "CLUSTERS_TO_ANALYZE = None  # None = analyze all clusters, or specify list [0, 1, 2]\n",
    "SAVE_RESULTS = True  # Save results to CSV files\n",
    "\n",
    "# ============================================================================\n",
    "# RUN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "if not INPUT_FILE.exists():\n",
    "    print(f\"\\nInput file not found: {INPUT_FILE}\")\n",
    "    print(\"Run Step 3 (Clustering) first\")\n",
    "else:\n",
    "    results = run_apriori_pipeline(\n",
    "        input_file=INPUT_FILE,\n",
    "        categorical_cols=CATEGORICAL_COLS,\n",
    "        binary_cols=BINARY_COLS,\n",
    "        min_support=MIN_SUPPORT,\n",
    "        min_confidence=MIN_CONFIDENCE,\n",
    "        clusters_to_analyze=CLUSTERS_TO_ANALYZE,\n",
    "        top_n=TOP_N_RULES,\n",
    "        save_results=SAVE_RESULTS,\n",
    "        output_dir=OUTPUT_DIR\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542de98",
   "metadata": {},
   "source": [
    "### Optional: Analyze Specific Cluster\n",
    "\n",
    "Run this cell to analyze a single cluster with custom parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a47e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Analyze cluster 0 with different parameters\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# df = pd.read_parquet(INPUT_FILE)\n",
    "# \n",
    "# cluster_results = analyze_cluster_rules(\n",
    "#     df=df,\n",
    "#     cluster_id=0,\n",
    "#     categorical_cols=CATEGORICAL_COLS,\n",
    "#     binary_cols=BINARY_COLS,\n",
    "#     min_support=0.3,  # Lower support threshold\n",
    "#     min_confidence=0.7,  # Higher confidence threshold\n",
    "#     top_n=20  # Show more rules\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
